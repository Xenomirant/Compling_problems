{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dba7c0d",
   "metadata": {},
   "source": [
    "# Домашнее задание № 10. Генерация текста"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f21d5e",
   "metadata": {},
   "source": [
    "### Задание 1 (10 баллов).\n",
    "\n",
    "В семинаре мы работали с датасетами инструкций alpaca и dolly. Они англоязычные. В домашке вам нужно создать аналогичный датасет на русском языке и обучить аналогичную модель на этом датасете. \n",
    "В качестве итогового результата у вас должна получится модель, которая может связно отвечать на русскоязычные инструкции на русском языке. Приведите как минимум три разных примера. Правильность ответов не так важна, так как вы скорее всего будете использовать небольшие модели, но текст должен быть не рандомным.\n",
    "\n",
    "Русскоязычный датасет инструкций должен быть больше 5 тысяч примеров. Он может быть основнован на alpaca/dolly (например, вы можете просто прогнать все через переводную модель, которая была на семинаре, или даже google translate). Или вы можете придумать способ создать аналогичный датасет каким-то другим способом (переделать открытые датасеты с помощью правил). Датасет может быть не уникальным, можно скооперироваться с одногруппниками и сделать один датасет на всех.\n",
    "\n",
    "Вы можете попробовать дообучать любую небольшую decoder-only модель. Скорее всего лучше всего будут работать модели, изначально обученные на русском языке (rugpt например). Но возможно даже модели вроде opt можно будет дообучить на русскоязычных инструкциях.\n",
    "\n",
    "Это задание гораздно менее определенное, по сравнению с предыдущими. Поэтому не стесняйтесь задавать дополнительные вопросы в чате или лично, если у вас возникнут трудности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d55f4538-b9cd-445e-8845-ac37edb4db9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from datasets import load_dataset\n",
    "import copy\n",
    "import logging\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional, Dict, Sequence\n",
    "import json\n",
    "import torch\n",
    "import transformers\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import Trainer\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdecb9db-0fa5-4d43-88a8-1a7476fba30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(\"INFO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3746873d-cc42-4f50-b944-f9ef75072fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just default index for ignore in CrossEntropy\n",
    "IGNORE_INDEX = -100\n",
    "DEFAULT_PAD_TOKEN = \"[PAD]\"\n",
    "DEFAULT_EOS_TOKEN = \"</s>\"\n",
    "DEFAULT_BOS_TOKEN = \"</s>\"\n",
    "DEFAULT_UNK_TOKEN = \"</s>\"\n",
    "# prompt templates\n",
    "PROMPT_DICT = {\n",
    "    \"prompt_input\": (\n",
    "        \"Ниже приведены инструкции, объясняющие задание вместе с необходимым контекстом. \\n\"\n",
    "        \"Ответь в соответствии с заданием. Постарайся сделать это последовательно и полно. \\n\\n\"\n",
    "        \"### Инструкция:\\n{instruction}\\n\\n### Контекст:\\n{input}\\n\\n### Ответ: \"\n",
    "    ),\n",
    "    \"prompt_no_input\": (\n",
    "        \"Ниже приведены инструкции, объясняющие задание.\"\n",
    "        \"Ответь в соответствии с заданием. Постарайся сделать это последовательно и полно. \\n\\n\"\n",
    "        \"### Инструкция:\\n{instruction}\\n\\n### Ответ: \"\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7506c481-7529-4c33-894e-1a5bc107898c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _tokenize_fn(strings: Sequence[str], tokenizer: transformers.PreTrainedTokenizer) -> Dict:\n",
    "    \"\"\"Tokenize a list of strings.\"\"\"\n",
    "    tokenized_list = [\n",
    "        tokenizer(\n",
    "            text,\n",
    "            return_tensors=\"pt\",\n",
    "            max_length=tokenizer.model_max_length,\n",
    "            truncation=True,\n",
    "        )\n",
    "        for text in strings\n",
    "    ]\n",
    "    input_ids = labels = [tokenized.input_ids[0] for tokenized in tokenized_list]\n",
    "    input_ids_lens = labels_lens = [\n",
    "        tokenized.input_ids.ne(tokenizer.pad_token_id).sum().item() for tokenized in tokenized_list\n",
    "    ]\n",
    "    return dict(\n",
    "        input_ids=input_ids,\n",
    "        labels=labels,\n",
    "        input_ids_lens=input_ids_lens,\n",
    "        labels_lens=labels_lens,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "289c9fd3-8b07-4a8c-b8ad-b9b663b656e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(\n",
    "    sources: Sequence[str],\n",
    "    targets: Sequence[str],\n",
    "    tokenizer: transformers.PreTrainedTokenizer,\n",
    ") -> Dict:\n",
    "    \"\"\"Preprocess the data by tokenizing.\"\"\"\n",
    "    # cat targets with outputs\n",
    "    examples = [s + t for s, t in zip(sources, targets)]\n",
    "    examples_tokenized, sources_tokenized = [_tokenize_fn(strings, tokenizer) for strings in (examples, sources)]\n",
    "    input_ids = examples_tokenized[\"input_ids\"]\n",
    "    # set up labels for text2text\n",
    "    labels = copy.deepcopy(input_ids)\n",
    "    # change label ids whithin source length to ignore during loss computation\n",
    "    for label, source_len in zip(labels, sources_tokenized[\"input_ids_lens\"]):\n",
    "        label[:source_len] = IGNORE_INDEX\n",
    "    return dict(input_ids=input_ids, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad73da78-7d40-4f41-833c-1ce29539e035",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupervisedDataset(Dataset):\n",
    "    \"\"\"Dataset for supervised fine-tuning.\"\"\"\n",
    "\n",
    "    def __init__(self, tokenizer: transformers.PreTrainedTokenizer):\n",
    "        super(SupervisedDataset, self).__init__()\n",
    "        logger.warning(\"Loading data...\")\n",
    "        list_data_dict = load_dataset(\"IlyaGusev/ru_turbo_alpaca\")[\"train\"]\n",
    "\n",
    "        logger.warning(\"Formatting inputs...\")\n",
    "        prompt_input, prompt_no_input = PROMPT_DICT[\"prompt_input\"], PROMPT_DICT[\"prompt_no_input\"]\n",
    "        sources = [\n",
    "            prompt_input.format_map(example) if example.get(\"input\", \"\") != \"\" else prompt_no_input.format_map(example)\n",
    "            for example in list_data_dict\n",
    "        ]\n",
    "        targets = [f\"{example['output']}{tokenizer.eos_token}\" for example in list_data_dict]\n",
    "\n",
    "        logger.warning(\"Tokenizing inputs... This may take some time...\")\n",
    "        data_dict = preprocess(sources, targets, tokenizer)\n",
    "\n",
    "        self.input_ids = data_dict[\"input_ids\"]\n",
    "        self.labels = data_dict[\"labels\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, i) -> Dict[str, torch.Tensor]:\n",
    "        return dict(input_ids=self.input_ids[i], labels=self.labels[i])\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorForSupervisedDataset(object):\n",
    "    \"\"\"Collate examples for supervised fine-tuning.\"\"\"\n",
    "\n",
    "    tokenizer: transformers.PreTrainedTokenizer\n",
    "\n",
    "    def __call__(self, instances: Sequence[Dict]) -> Dict[str, torch.Tensor]:\n",
    "        input_ids, labels = tuple([instance[key] for instance in instances] for key in (\"input_ids\", \"labels\"))\n",
    "        input_ids = torch.nn.utils.rnn.pad_sequence(\n",
    "            input_ids, batch_first=True, padding_value=self.tokenizer.pad_token_id\n",
    "        )\n",
    "        # pad with IGNORE INDEX as well till the end\n",
    "        labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value=IGNORE_INDEX)\n",
    "        # return dict with attension mask for padded input values\n",
    "        return dict(\n",
    "            input_ids=input_ids,\n",
    "            labels=labels,\n",
    "            attention_mask=input_ids.ne(self.tokenizer.pad_token_id),\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c0e374-61eb-489d-89ff-1326bbffc333",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"facebook/opt-125m\"\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        max_length=512,\n",
    "        cache_dir=\"huggingface_cache\",\n",
    "    )\n",
    "\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "    model_name,\n",
    "    cache_dir=\"huggingface_cache\",\n",
    "    model_max_length=512,\n",
    "    padding_side=\"right\",\n",
    "    use_fast=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fd2099c-9feb-4298-ab06-39608a8ab1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "/home/local/.local/lib/python3.10/site-packages/datasets/load.py:1454: FutureWarning: The repository for IlyaGusev/ru_turbo_alpaca contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/IlyaGusev/ru_turbo_alpaca\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "Formatting inputs...\n",
      "Tokenizing inputs... This may take some time...\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SupervisedDataset(tokenizer=tokenizer,)\n",
    "data_collator = DataCollatorForSupervisedDataset(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bfbecb-cf93-4692-ba0e-a3ba9f9d0ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_args = transformers.TrainingArguments(\n",
    "    learning_rate=3e-5, \n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    # gradient_checkpointing=True,\n",
    "    gradient_accumulation_steps=1,\n",
    "    # fp16=True,\n",
    "    evaluation_strategy='no',\n",
    "    weight_decay=0.,\n",
    "    warmup_ratio=0.05,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    save_strategy='no',\n",
    "    logging_steps=1000,\n",
    "    output_dir=\"opt125_instruct_ft\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdda29c-e300-4078-8a06-9710a4c4b32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model=model, \n",
    "                 tokenizer=tokenizer, \n",
    "                 args=train_args,\n",
    "                 train_dataset=train_dataset, \n",
    "                 eval_dataset=None, \n",
    "                 data_collator=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d22c28c-af99-4746-9f5e-390d6a95e438",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434da399-a09d-4531-9190-92e5fbaf828b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('opt125_instruct_ft/model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a77b795e-c8c5-46c8-a86f-3150d080f4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_for_instruction(instruct, text, model):  \n",
    "\n",
    "    inputs = tokenizer([instruct.format(text)], \n",
    "                        return_tensors=\"pt\", padding=True).to(\"cuda\")\n",
    "\n",
    "    output_sequences = model.generate(\n",
    "        # this parameters are also important but you can read about them in the docs and just try changing them\n",
    "        num_beams=7,\n",
    "        max_length=1024,\n",
    "    # no_repeat_ngram_size=3, \n",
    "    repetition_penalty= 8.0,\n",
    "    # length_penalty=0.01,\n",
    "    #  early_stopping=True,\n",
    "    do_sample=False, \n",
    "    # top_k=15, \n",
    "    # top_p=0.8, \n",
    "    # early_stopping=False,\n",
    "    #     num_return_sequences=3,\n",
    "    num_return_sequences=1,\n",
    "    input_ids=inputs[\"input_ids\"],\n",
    "    attention_mask=inputs[\"attention_mask\"],\n",
    "    )\n",
    "    summaries = tokenizer.batch_decode(output_sequences, skip_special_tokens=True)\n",
    "    return summaries[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f1adaa-a839-4d3b-a298-41ea1c83a820",
   "metadata": {},
   "source": [
    "С этой моделью скорее всего выйдет плохо, поскольку она плохо заточена под русский, а за обучение на инструкциях выучить достаточно она вряд ли могла бы. Зато можно попробовать погенерировать разный бред"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8dcc99f9-ca3d-4019-95f0-df03dc9b2078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# забыл сохранить модель, но оно все равно работало плохо, так что пусть разве что на память остается"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcbe63d-42ba-4184-9085-f47b4453742d",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruct = \"Напиши, как сделать омлет.\"\n",
    "text = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c726e4a-a5d5-481c-88fe-015ae3b5252f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_for_instruction(instruct, text, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d973809-9f0d-4f12-b096-04db420ae3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_for_instruction(instruct, text, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72eb739-af77-4c2b-9319-4b87f3c210a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruct = \"Предложи заголовок для текста ниже. Текст: {}\"\n",
    "text = \"\"\"Исходная точка, для которой требуется интерпретация, выбирается из набора данных. \n",
    "Это может быть любой пример (например, строка данных для табличных данных, изображение, текст и т.д.), \n",
    "для которого было сделано предсказание сложной модели. Эта точка служит центром локального анализа и основой для генерации новых, \n",
    "возмущенных примеров данных. Возмущения создаются путем внесения небольших изменений в исходные данные. \n",
    "Эти изменения могут быть реализованы различными способами, в зависимости от типа данных\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18761c1-6913-4425-b918-335543d1d808",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_for_instruction(instruct, text, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db37f2c-fdb9-4a53-ade4-07a6d53f877c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d92c401-ccc0-4a1a-9490-f4db9439fc13",
   "metadata": {},
   "source": [
    "### try other model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0733f8d1-efa4-4604-8e97-27ba251c6460",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"ai-forever/rugpt3small_based_on_gpt2\",\n",
    "                                                      max_len=512,\n",
    "                                                      padding_side=\"right\",\n",
    "                                                      cache_dir=\"huggingface_cache\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b7e1a080-2fcf-496c-9e1d-4e318806e5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7403d95-4a1d-4ae8-be00-7d3ed2eb7b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "/usr/local/lib/python3.10/dist-packages/datasets/load.py:1461: FutureWarning: The repository for IlyaGusev/ru_turbo_alpaca contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/IlyaGusev/ru_turbo_alpaca\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "Formatting inputs...\n",
      "Tokenizing inputs... This may take some time...\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SupervisedDataset(tokenizer=tokenizer,)\n",
    "data_collator = DataCollatorForSupervisedDataset(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6f574af-d45a-4675-af86-8e0dd60daadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = transformers.AutoModelForCausalLM.from_pretrained(\"ai-forever/rugpt3small_based_on_gpt2\",\n",
    "                                         cache_dir=\"huggingface_cache\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bb18db9-3d18-4c96-8d1e-6dca59bdf8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_args = transformers.TrainingArguments(\n",
    "    learning_rate=5e-5,\n",
    "    do_eval=False,\n",
    "    do_predict=False,\n",
    "    num_train_epochs=3,\n",
    "    dataloader_num_workers=4,\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_checkpointing=True,\n",
    "    gradient_accumulation_steps=8,\n",
    "    evaluation_strategy='no',\n",
    "    weight_decay=0.,\n",
    "    warmup_ratio=0.1,\n",
    "    optim=\"adafactor\",\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    save_strategy='no',\n",
    "    logging_steps=200,\n",
    "    output_dir=\"rugpt_instruct_ft\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a45b12ee-e737-49a8-9ed1-2b6d0bd41ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model=model, \n",
    "                 tokenizer=tokenizer, \n",
    "                 args=train_args,\n",
    "                 train_dataset=train_dataset, \n",
    "                 eval_dataset=None, \n",
    "                 data_collator=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70760fd2-2bb5-45aa-9ea5-51d940fb6d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mxenomirant\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/app/CCLP/wandb/run-20240417_172929-53t7bg1t</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/xenomirant/huggingface/runs/53t7bg1t' target=\"_blank\">glamorous-bee-31</a></strong> to <a href='https://wandb.ai/xenomirant/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/xenomirant/huggingface' target=\"_blank\">https://wandb.ai/xenomirant/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/xenomirant/huggingface/runs/53t7bg1t' target=\"_blank\">https://wandb.ai/xenomirant/huggingface/runs/53t7bg1t</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2796' max='2796' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2796/2796 57:16, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.430200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.160500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.098900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.065700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.972500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>1.851500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>1.832900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>1.830900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>1.822700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.714600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>1.667000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>1.654300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>1.666300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2796, training_loss=1.8876232643836899, metrics={'train_runtime': 3440.327, 'train_samples_per_second': 26.005, 'train_steps_per_second': 0.813, 'total_flos': 7684375133952000.0, 'train_loss': 1.8876232643836899, 'epoch': 3.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed4d8cbd-edd3-4148-9448-cf6eab23bb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('rugpt_instruct_ft/model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6b17ef5d-23f6-45f6-bd5b-26f304ffd920",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_for_instruction(instruct, text, model):  \n",
    "\n",
    "    inputs = tokenizer([instruct.format(text)], \n",
    "                        return_tensors=\"pt\", padding=True).to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        output_sequences = model.generate(\n",
    "            # this parameters are also important but you can read about them in the docs and just try changing them\n",
    "            num_beams=7,\n",
    "            max_length=1024,\n",
    "        # no_repeat_ngram_size=3, \n",
    "        repetition_penalty= 8.0,\n",
    "        length_penalty=0.01,\n",
    "        #  early_stopping=True,\n",
    "        do_sample=True, \n",
    "        # top_k=15, \n",
    "        # top_p=0.8, \n",
    "        early_stopping=True,\n",
    "        #     num_return_sequences=3,\n",
    "        num_return_sequences=1,\n",
    "        input_ids=inputs[\"input_ids\"],\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "        )\n",
    "    summaries = tokenizer.batch_decode(output_sequences, skip_special_tokens=True)\n",
    "    return summaries[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "54d8fff3-89ec-47fa-a4c3-3493461c1b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruct = \"Напиши, как сделать омлет.\"\n",
    "text = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7c45bb76-e0e5-43b2-8293-e4aef136df2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:90: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Напиши, как сделать омлет.  Для приготовления омлета нужно разогреть сковороду на среднем огне и добавить немного сливочного масла.  После того, как омлет готов, его можно подавать горячими или холодными. \\n Омлет - это вкусное блюдо, которое всегда получается сытным и ароматным.  Он может быть приготовлен из различных ингредиентов, таких как яйца, молоко, сахар, мука, соль и т. д. Чтобы приготовить омлет, необходимо сначала нагреть сковороду до тех пор, пока она не станет золотисто-коричневого цвета.  Затем добавьте в сковороду мелко нарезанные овощи (например, помидоры, огурцы) и жарьте их с обеих сторон до золотистого цвета.  Когда омлет будет готов, посыпьте его сверху тертым пармезаном и украсьте свежими травами по вкусу. Приятного аппетита! ]]><img src=\"https://i.stack.imgur.com/t6R7k.png\" border=\"0\" width=\"600\" height=\"450\" /></a>'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_for_instruction(instruct, text, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8b5c44df-9127-4d2f-bc60-59cc0a61d2a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Напиши, как сделать омлет.  Чтобы приготовить омлет, нужно сначала разогреть сковороду на среднем огне и добавить немного оливкового масла.  Когда омлет будет готов, обжарьте его на сковороде до золотистой корочки.  Добавьте в сковороду мелко нарезанный лук и жарьте еще несколько минут.  Подавайте с рисом или сметаной.  Омлет получается очень вкусным! \\n Оладьи из куриного мяса - это отличное блюдо для тех, кто хочет разнообразить свой рацион.  Для этого вам понадобятся: куринное филе, яйца, сыр пармезан, чеснок, соль и перец по вкусу.  Сначала сварите куриное филе в подсоленной воде до мягкости.  Разогрейте сковороду на среднем огне и добавьте небольшое количество сливочного масла.  Посыпьте яйцо солью и перцем по вкусу.  Нарежьте куриное филе на порции и выложите их на противень.  Поставьте запекаться в духовке при температуре 180 градусов Цельсия около 20-25 минут.  Готовые оладьи можно подавать со свежими фруктами или йогуртом.  Приятного аппетита! \\n Яичница — это одно из самых любимых блюд моей семьи.  Это простое и быстрое блюдо, которое идеально подходит для любого случая.  Ингредиенты: 4 яйца, 1 стакан муки, 2 столовые ложки растительного масла, 100 г сыра пармезана, щепотка черного перца чили (можно использовать любые другие ингредиенты).  Тесто разделите на три равные части и раскатайте каждую на большую круглую форму.  Раскатайте каждый слой теста так, чтобы он был толщиной примерно 3 см. Выложите яичную смесь на тарелку и посыпьте сверху тертым пармезаном.  Наслаждайтесь своим любимым омлетом! \\n Овсяная каша является одним из моих любимых продуктов.  Она состоит из овсяных хлопьев, сахарной пудры, меда, соли и васаби.  В овсянку добавляют измельченный миндаль, кокосовую стружу, семена льна и т.д., а затем смешивают ее с сахаром и корицей.  Получается густая каша без добавления каких-либо дополнительных ингредиентов.  Очень рекомендую эту кашу всем, кто заботится о своем здоровье и здоровом пищеварении. \\n Сегодня у меня есть много способов приготовления блинов.  Например, я люблю экспериментировать с различными вариантами начинки, такими как кленовый сироп, капучино, тефтелированный бургер Кинг-Кайнбрукс и многие другие.  Одним из лучших вариантов может быть творожный пирог с карамелизированными яблоками вместо вареного хлеба.  Или просто испечь что-то легкое и легкоусваивающуюся выпечку под названием \"кокосовое молоко\".  Все зависит от ваших вкусов и предпочтений.  Присоединяйтесь к нашему новому кулинарному сообществу! \\n\\n Главная > Рецепты > Кулинарные рецепты > Как приготовить тесто для пиццы <a href=\"#\"></a>? \\n Приготовить тесто для пиццы >> a href=\"#\"><a href=\"#\">как приготовить тесто для пиццы <a href=\"#\"><a href=\"#\">Как приготовить тесто для пиццы <a href=\"#\"><a href=\"#\"><a href=\"#\"><a href=\"#\"><a href=\"#\"><a href=\"#\"><a href=\"#\"><a href=\"#\"><a href=\"#\"><a href=\"#\"><a href=\"#\"><a href=\"#\"><a href=\"#\"><a href=\"#\"><a href=\"#'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_for_instruction(instruct, text, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eb4a1d4b-1469-4963-a36d-f08a5e7f27a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruct = \"Предложи заголовок для текста ниже. Текст: {}\"\n",
    "text = \"\"\"Графы и комплексы можно описывать признаковыми описаниями для вершин либо симплексов их составляющих – степенями, центральностями, коэффициентами кластеризации и т.д. Для графов существует признаковые описания основанные поиске графлетов – элементарных подграфов на небольшом (3-5) количестве вершин [Ribeiro2019]. Тогда каждая вершина графа описывается количеством ее вхождений в во все элементарные подграфы, а также количеством ее вхождения в эквивалентные до перестановки вершины этих подграфов, так называемые орбиты.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8c1321ae-09e7-4bcc-a1e1-a9eaee1e1f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Предложи заголовок для текста ниже. Текст: Графы и комплексы можно описывать признаковыми описаниями для вершин либо симплексов их составляющих – степенями, центральностями, коэффициентами кластеризации и т.д. Для графов существует признаковые описания основанные поиске графлетов – элементарных подграфов на небольшом (3-5) количестве вершин [Ribeiro2019]. Тогда каждая вершина графа описывается количеством ее вхождений в во все элементарные подграфы, а также количеством ее вхождения в эквивалентные до перестановки вершины этих подграфов, так называемые орбиты.\\nГрафы могут быть классифицированы по различным признакам, таким как цветность, размер шрифта, форма именительного паскаля и т.д. В зависимости от того, какие признаки обозначают вершину или комплекс, каждый признак может указывать на его принадлежность к какой-либо из категорий. Например, если у нас есть <<a href=\"#\"><a href=\"\"></a>, то мы можем использовать <<a href=\"\"><a href=\"\", чтобы найти <<a href=\"\"><a href=\"\"><a href=\"\"></a> с помощью <<a href=\"\"><a href=\"?\"><a href=\"\"><b></a>.</span>). Важно понимать, что каждое значение является характеристикой чего-то конкретного объекта, поэтому не следует забывать о том, что каждому параметру соответствует только одно значение. Если вы хотите узнать больше об этом предмете, пожалуйста, свяжитесь со мной любым удобным для вас способом. Спасибо за ваше время! До скорой встречи!'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_for_instruction(instruct, text, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c44dfbea-2d3f-4d10-8c21-6e48389bc14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruct = \"Посчитай, сколько ног у двух лошадей.\"\n",
    "text = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9a287705-ef63-4da2-b5ae-f5c03922cf81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Посчитай, сколько ног у двух лошадей.\\n\\nВ общем, я не знаю, что делать с этими двумя лошадьми и почему они так сильно отличаются друг от друга? Может быть, это связано с тем, что две лошади имеют разный темперамент или как-то по-разному реагируют на разные условия окружающей среды? Я думаю, что лучше всего обратиться к ветеринару за помощью в поиске причины их различий.\\n\\nС уважением, [ваше мнение].\\n[Ваше мнение о том, какие факторы влияют на различия в поведении этих двух лошадей.]\\n[Твое мнение о том, какой фактор может повлиять на различие в поведении этой двух лошадей]\\n[Твое мнение о том, каким образом эти две лошади могут влиять на поведение других лошадей]\\n[Твое мнение о том, какое влияние оказывает разница в поведении обеих лошадей]\\n[Твое мнение о том, какую роль играют изменения в поведении этих двух лошадей]\\n[Твое мнение о том, какая роль играет изменение в поведении этих двух лошадей]'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_for_instruction(instruct, text, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67894d2b-8fe2-48fb-9a8e-981bea7f24c5",
   "metadata": {},
   "source": [
    "Генерация сразу с рекламной интеграцией -- можно считать, готовая коммерческая модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4807e8a1-2218-4e3e-83f0-c81fa178c58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruct = \"Расскажи, что стоит делать, чтобы лучше засыпать.\"\n",
    "text = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2fa0d8e1-7c2c-47bf-9450-67ef648ef4f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Расскажи, что стоит делать, чтобы лучше засыпать.  Что нужно сделать, чтобы улучшить качество сна? \\n Для улучшения качества сна можно использовать различные методы: медитация, глубокое дыхание, йога, ароматерапия и т.д. Важно помнить, что сон - это не только физическое состояние, но и психологическое состояние, поэтому важно уделить внимание своему сну как можно больше времени для отдыха и релаксации.  Если вы хотите улучшить качество сна, обратитесь к специалистам за помощью или проконсультируйтесь у них по этому вопросу. \\n Добавить комментарий Отменить ответ \\n\\n Вы можете войти на сайт, если вы зарегистрированы в одном из этих сервисов: \\n Используйте вашу учетную запись VKontakte для входа на сайт. \\n Используйте вашу учетную запись на Twitter.com для входа на сайт. \\n Используйте вашу учетную запись на Facebook.com для входа на сайт. \\n Используйте вашу учетную запись Google для входа на сайт. \\n Используйте вашу учетную запись Мой Мир@Mail.ru для входа на сайт. \\n Используйте вашу учетную запись на Twitter.com для входа на сайт. \\n Используйте вашу учетную запись на Facebook.com для входа на сайт. \\n Используйте вашу учетную запись Google для входа на сайт. \\n Используйте вашу учетную запись на YouTube для входа на сайт. \\n Используйте вашу учетную запись Мой Мир@Mail.ru для входа на сайт. \\n Используйте вашу учетную запись Наворовцева для входа на сайт. \\n Используйте вашу учетную запись на Gmail.com для входа на сайт. \\n Используйте вашу учетную запись на Telegram для входа на сайт. \\n Используйте вашу учетную запись на Twitter.com для входа на сайт. \\n Используйте вашу учетную запись на Facebook.com для входа на сайт. \\n Используйте вашу учетную запись на Rosetta Stone для входа на сайт. \\n Используйте вашу учетную запись Google для входа на сайт. \\n Используйте вашу учетную запись Odnoklassniki для входа на сайт. \\n Используйте вашу учетную запись VKontakte для входа на сайт. \\n Используйте вашу учетную запись на Yandex.ru для входа на сайт. \\n Используйте вашу учетную запись Masta для входа на сайт. \\n Используйте вашу учетную запись на Foursquare для входа на сайт. \\n Используйте вашу учетную запись на Twitch для входа на сайт. \\n Используйте вашу учетную запись WordPress для входа на сайт. \\n Используйте вашу учетную запись MySQL для входа на сайт. \\n Используйте вашу учетную запись OpenAI для входа на сайт. \\n Используйте вашу учетную запись Hangouts для входа на сайт. \\n Используйте вашу учетную запись ВКонтакте для входа на сайт. \\n Используйте вашу учетную запись RSS для входа на сайт. \\n Используйте вашу учетную запись Svoboda для входа на сайт. \\n Используйте вашу учетную запись Битрикс24 для входа на сайт. \\n Используйте вашу учетную запись PrivateNS для входа на сайт. \\n Используйте вашу учетную запись PayPal для входа на сайт. \\n Используйте вашу учетную запись Apple для входа на сайт. \\n Используйте вашу учетную запись Google для входа на сайт. \\n Используйте вашу учетную запись Яндекс для входа на сайт. \\n Используйте вашу учетную запись Mac для входа на сайт. \\n Используйте вашу учетную запись Google для входа на сайт. \\n Используйте вашу учетную запись Mail для входа на сайт. \\n Используйте вашу учетную запись DomainName для входа на сайт. \\n Используйте вашу учетную запись Windows для входа на сайт. \\n Используйте вашу учетную запись Karma для входа на сайт. \\n Используйте вашу учетную запись Cookies для входа на сайт. \\n Используйте вашу учетную запись Wikipedia для входа на сайт. \\n Используйте вашу учетную запись Microsoft для входа на сайт. \\n Используйте вашу учетную запись VKontakte для входа на сайт. \\n Используйте вашу учетную запись Одноклассники для входа на сайт. \\n Используйте вашу учетную запись vkontakte для входа на сайт. \\n Используйте вашу учетную запись \"Входящие\" для входа на сайт. \\n Используйте вашу учетную запись Banki для входа на сайт. \\n Используйте вашу учетную запись E-mail для входа на сайт. \\n Используйте вашу учетную запись Google для входа на сайт. \\n Используйте вашу учетную запись на Newsletter для входа на сайт. \\n Используйте вашу учетную запись Android для входа на сайт. \\n Используйте вашу учетную запись Instagram для входа на сайт. \\n Используйте вашу учетную запись Podosita для входа на сайт. \\n Используйте вашу учетную запись Google для входа на сайт. \\n Используйте вашу учетную запись с помощью социальных сетей. \\n Используйте вашу учетную запись Яндекса для входа на сайт. \\n Используйте вашу учетную запись OK! для входа на сайт. \\n Используйте вашу учетную запись Login для входа на сайт. \\n Используйте вашу учетную запись URL для входа на сайт. \\n Используйте вашу учетную запись электронной почты для входа на сайт. \\n Используйте вашу учетную запись Reactor для входа на сайт. \\n Используйте вашу учетную запись Bing для входа на сайт. \\n Используйте вашу учетную запись IE для входа на сайт. \\n Используйте вашу учетную запись от своего мобильного телефона. \\n Используйте вашу учетную запись Гайтар для входа на сайт. \\n Используйте вашу учетную запись о посещенных вами сайтах'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_for_instruction(instruct, text, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
