{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b20f786e",
   "metadata": {},
   "source": [
    "# Домашнее задание № 2. Мешок слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "129c4d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from razdel import tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf72d19",
   "metadata": {},
   "source": [
    "## Задание 1 (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a045e99",
   "metadata": {},
   "source": [
    "У векторайзеров в sklearn есть встроенная токенизация на регулярных выражениях. Найдите способо заменить её на кастомную токенизацию"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b4d453",
   "metadata": {},
   "source": [
    "Обучите векторайзер с дефолтной токенизацией и с токенизацией razdel.tokenize. Обучите классификатор (любой) с каждым из векторизаторов. Сравните метрики и выберете победителя. \n",
    "\n",
    "(в вашей тетрадке должен быть код обучения и все метрики; если вы сдаете в .py файлах то сохраните полученные метрики в отдельном файле или в комментариях)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7455ade-284a-4d35-8a5a-826e4ddc566d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  labeled.csv.zip\n",
      "  inflating: labeled.csv             \n",
      "  inflating: __MACOSX/._labeled.csv  \n"
     ]
    }
   ],
   "source": [
    "! unzip -o labeled.csv.zip\n",
    "! rm -rf __MACOSX/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4314de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('labeled.csv')\n",
    "\n",
    "stops = stopwords.words(\"russian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbffbbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.toxic\n",
    "\n",
    "X = data.drop(columns=\"toxic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "808ddd7b-fc58-4bf7-b033-f84a7f8ceef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "razdel_tokenize = lambda x: [item.text for item in list(tokenize(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d2477b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_tokenizer = CountVectorizer()\n",
    "\n",
    "razdel_tokenizer = CountVectorizer(stop_words=stops, tokenizer=razdel_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f78899d-caab-42c8-84b8-2c1e9c752fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59055c5b-77c4-481c-9d61-4fd6ec6f2a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_def_count = default_tokenizer.fit_transform(X_train.comment)\n",
    "X_test_def_count = default_tokenizer.transform(X_test.comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3c09e90-cec9-4354-95e0-24c784f4ae2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_razdel_count = razdel_tokenizer.fit_transform(X_train.comment)\n",
    "X_test_razdel_count = razdel_tokenizer.transform(X_test.comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e381d9b-a6e1-485f-a1e2-5bf6dbabe538",
   "metadata": {},
   "source": [
    "#### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f391890e-80f1-4653-a5b4-cf9a4b68a26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f448c2b-322a-4e4b-9b70-65b917fd56e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, **kwargs) -> None:\n",
    "\n",
    "    model.fit(kwargs[\"X_train\"], kwargs[\"y_train\"])\n",
    "\n",
    "    pred_def = model.predict(kwargs[\"X_test\"])\n",
    "\n",
    "    print(f'Confusion matrix for the model: \\n{ confusion_matrix(kwargs[\"y_test\"], pred_def) }')\n",
    "\n",
    "    print(\"\\n----------------------------\\n\")\n",
    "\n",
    "    print(classification_report(kwargs[\"y_test\"], pred_def))\n",
    "\n",
    "    print(f'Overall f1-score is {f1_score(kwargs[\"y_test\"], pred_def)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf6d501-c774-4361-9a81-a78aba9d3104",
   "metadata": {},
   "source": [
    "**Trying gradient boosting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad5b2fb0-0001-434a-adab-ad6b54c36c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_grad = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1e80fba-c1a5-4fa8-a571-fc2b6f03d14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for the model: \n",
      "[[2789   78]\n",
      " [ 987  470]]\n",
      "\n",
      "----------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.97      0.84      2867\n",
      "         1.0       0.86      0.32      0.47      1457\n",
      "\n",
      "    accuracy                           0.75      4324\n",
      "   macro avg       0.80      0.65      0.65      4324\n",
      "weighted avg       0.78      0.75      0.71      4324\n",
      "\n",
      "Overall f1-score is 0.4688279301745636\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(cls_grad, X_train = X_train_def_count, X_test = X_test_def_count, y_train = y_train, y_test = y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "929222e6-d47e-49c9-929f-0cab95c2b178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for the model: \n",
      "[[2781   86]\n",
      " [1074  383]]\n",
      "\n",
      "----------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.97      0.83      2867\n",
      "         1.0       0.82      0.26      0.40      1457\n",
      "\n",
      "    accuracy                           0.73      4324\n",
      "   macro avg       0.77      0.62      0.61      4324\n",
      "weighted avg       0.75      0.73      0.68      4324\n",
      "\n",
      "Overall f1-score is 0.39771547248182765\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(cls_grad, X_train = X_train_razdel_count, X_test = X_test_razdel_count, y_train = y_train, y_test = y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdab0906-9e40-46d3-81c2-57281bd02b0c",
   "metadata": {},
   "source": [
    "**Let's try random forest then**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6b044ef-4463-441a-9fd3-228dd44b111c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_forest = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65136175-5b8a-4e93-b987-a3634d3cfc65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for the model: \n",
      "[[2687  180]\n",
      " [ 790  667]]\n",
      "\n",
      "----------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.94      0.85      2867\n",
      "         1.0       0.79      0.46      0.58      1457\n",
      "\n",
      "    accuracy                           0.78      4324\n",
      "   macro avg       0.78      0.70      0.71      4324\n",
      "weighted avg       0.78      0.78      0.76      4324\n",
      "\n",
      "Overall f1-score is 0.5789930555555556\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(cls_forest, X_train = X_train_def_count, X_test = X_test_def_count, y_train = y_train, y_test = y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea17f5e3-203b-4230-ae52-c28d75cc8649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for the model: \n",
      "[[2790   77]\n",
      " [ 961  496]]\n",
      "\n",
      "----------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.97      0.84      2867\n",
      "         1.0       0.87      0.34      0.49      1457\n",
      "\n",
      "    accuracy                           0.76      4324\n",
      "   macro avg       0.80      0.66      0.67      4324\n",
      "weighted avg       0.78      0.76      0.72      4324\n",
      "\n",
      "Overall f1-score is 0.4886699507389163\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(cls_forest, X_train = X_train_razdel_count, X_test = X_test_razdel_count, y_train = y_train, y_test = y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e15186-7e62-42a3-8709-384496ad7a7c",
   "metadata": {},
   "source": [
    "Похоже, результат в любом случае становится хуже, но, вероятно, это может служить не столько индикатором худшего качества разметки, сколько индикатором недостаточного качества эмбедингов или обобщающей способности модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5b8f53-d99e-4cf5-84c9-ed3b74c35368",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3137de7-4be4-4c0e-bcbb-552d23d1f8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_tokenizer = TfidfVectorizer()\n",
    "\n",
    "razdel_tokenizer = TfidfVectorizer(stop_words=stops, tokenizer=razdel_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8a3a66d-ec7c-438d-9f61-c8a5fcf083f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_def_tfidf = default_tokenizer.fit_transform(X_train.comment)\n",
    "X_test_def_tfidf = default_tokenizer.transform(X_test.comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b1dbe22-5ca4-40e9-859d-703bf65404ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_razdel_tfidf = razdel_tokenizer.fit_transform(X_train.comment)\n",
    "X_test_razdel_tfidf = razdel_tokenizer.transform(X_test.comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c609bec-701b-4b29-aa73-96dd079a23db",
   "metadata": {},
   "source": [
    "**Test gradient boosing with TfidfVectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1294b0e3-5974-4cf3-b80d-2bce9ffbebf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for the model: \n",
      "[[2784   83]\n",
      " [1003  454]]\n",
      "\n",
      "----------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.97      0.84      2867\n",
      "         1.0       0.85      0.31      0.46      1457\n",
      "\n",
      "    accuracy                           0.75      4324\n",
      "   macro avg       0.79      0.64      0.65      4324\n",
      "weighted avg       0.77      0.75      0.71      4324\n",
      "\n",
      "Overall f1-score is 0.45536609829488467\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(cls_grad, X_train = X_train_def_tfidf, X_test = X_test_def_tfidf, y_train = y_train, y_test = y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a20cfa84-7d52-4b71-b8ef-4d8675b8548a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for the model: \n",
      "[[2787   80]\n",
      " [1095  362]]\n",
      "\n",
      "----------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.97      0.83      2867\n",
      "         1.0       0.82      0.25      0.38      1457\n",
      "\n",
      "    accuracy                           0.73      4324\n",
      "   macro avg       0.77      0.61      0.60      4324\n",
      "weighted avg       0.75      0.73      0.68      4324\n",
      "\n",
      "Overall f1-score is 0.3812532912058978\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(cls_grad, X_train = X_train_razdel_tfidf, X_test = X_test_razdel_tfidf, y_train = y_train, y_test = y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f7b63a-9a95-4642-b3d4-2cfc67da90ce",
   "metadata": {},
   "source": [
    "**And with random forest again**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d49d4f8-9983-45a2-a45b-ea51dafd1ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for the model: \n",
      "[[2702  165]\n",
      " [ 782  675]]\n",
      "\n",
      "----------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.94      0.85      2867\n",
      "         1.0       0.80      0.46      0.59      1457\n",
      "\n",
      "    accuracy                           0.78      4324\n",
      "   macro avg       0.79      0.70      0.72      4324\n",
      "weighted avg       0.78      0.78      0.76      4324\n",
      "\n",
      "Overall f1-score is 0.5877231171092729\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(cls_forest, X_train = X_train_def_count, X_test = X_test_def_count, y_train = y_train, y_test = y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "40ed9b07-ed05-4300-b656-71f32ccbd4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for the model: \n",
      "[[2798   69]\n",
      " [ 963  494]]\n",
      "\n",
      "----------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.98      0.84      2867\n",
      "         1.0       0.88      0.34      0.49      1457\n",
      "\n",
      "    accuracy                           0.76      4324\n",
      "   macro avg       0.81      0.66      0.67      4324\n",
      "weighted avg       0.79      0.76      0.72      4324\n",
      "\n",
      "Overall f1-score is 0.48910891089108915\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(cls_forest, X_train = X_train_razdel_count, X_test = X_test_razdel_count, y_train = y_train, y_test = y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe1eaa3-08f3-4150-8b7a-6785d90a25e1",
   "metadata": {},
   "source": [
    "Хм, tf-idf лишь подтвердил, что с разделовской токенизацией, классифицирующая способность становится хуже..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b9076e",
   "metadata": {},
   "source": [
    "## Задание 2 (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e25357",
   "metadata": {},
   "source": [
    "Обучите 2 любых разных классификатора из семинара. Предскажите токсичность для текстов из тестовой выборки (используйте одну и ту же выборку для обоих классификаторов) и найдите 10 самых токсичных для каждого из классификаторов. Сравните получаемые тексты - какие тексты совпадают, какие отличаются, правда ли тексты токсичные?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de962ad",
   "metadata": {},
   "source": [
    "Требования к моделям:   \n",
    "а) один классификатор должен использовать CountVectorizer, другой TfidfVectorizer  \n",
    "б) у векторазера должны быть вручную заданы как минимум 5 параметров (можно ставить разные параметры tfidfvectorizer и countvectorizer)  \n",
    "в) у классификатора должно быть задано вручную как минимум 2 параметра (по возможности)  \n",
    "г)  f1 мера каждого из классификаторов должна быть минимум 0.75  \n",
    "\n",
    "*random_seed не считается за параметр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ac0a5471",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer(tokenizer=razdel_tokenize, \n",
    "                            ngram_range=(1,3),\n",
    "                            max_df = .05,\n",
    "                            min_df = 1e-4, \n",
    "                            max_features=500,\n",
    "                            stop_words=stops,\n",
    "                            sublinear_tf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "50407e7d-6c2b-4be2-b638-8049e34e2c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = TfidfVectorizer(tokenizer=razdel_tokenize, \n",
    "                            ngram_range=(1,3),\n",
    "                            max_df = .05,\n",
    "                            min_df = 15,\n",
    "                            max_features=500,\n",
    "                            stop_words=stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "de3429f9-e85d-4641-b1e2-6820c9e059a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf = tfidf_vect.fit_transform(X_train.comment)\n",
    "X_test_tfidf = tfidf_vect.transform(X_test.comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2965e014-bb85-4dd2-bdcd-13baf9b3c4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_count = count_vect.fit_transform(X_train.comment)\n",
    "X_test_count = count_vect.transform(X_test.comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "745bd58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import CategoricalNB\n",
    "\n",
    "cls_forest = RandomForestClassifier(n_estimators=500, max_depth=25, min_samples_leaf=2, class_weight=\"balanced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "fcdec881-d6c3-4294-bd18-e055bc011f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for the model: \n",
      "[[1519 1348]\n",
      " [ 216 1241]]\n",
      "\n",
      "----------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.53      0.66      2867\n",
      "         1.0       0.48      0.85      0.61      1457\n",
      "\n",
      "    accuracy                           0.64      4324\n",
      "   macro avg       0.68      0.69      0.64      4324\n",
      "weighted avg       0.74      0.64      0.64      4324\n",
      "\n",
      "Overall f1-score is 0.6134453781512604\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(cls_forest, X_train = X_train_count.toarray(), X_test = X_test_count.toarray(), y_train = y_train, y_test = y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "90311fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for the model: \n",
      "[[1508 1359]\n",
      " [ 209 1248]]\n",
      "\n",
      "----------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.53      0.66      2867\n",
      "         1.0       0.48      0.86      0.61      1457\n",
      "\n",
      "    accuracy                           0.64      4324\n",
      "   macro avg       0.68      0.69      0.64      4324\n",
      "weighted avg       0.74      0.64      0.64      4324\n",
      "\n",
      "Overall f1-score is 0.6141732283464567\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(cls_forest, X_train = X_train_tfidf.toarray(), X_test = X_test_tfidf.toarray(), y_train = y_train, y_test = y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f228c3e",
   "metadata": {},
   "source": [
    "## Задание 3 (4 балла - 1 балл за каждый классификатор)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566929b7",
   "metadata": {},
   "source": [
    "Для классификаторов Logistic Regression, Decision Trees, Naive Bayes, RandomForest найдите способ извлечь важность признаков для предсказания токсичного класса. Сопоставьте полученные числа со словами (или нграммами) в словаре и найдите топ - 5 \"токсичных\" слов для каждого из классификаторов. \n",
    "\n",
    "Важное требование: в топе не должно быть стоп-слов. Для этого вам нужно будет правильным образом настроить векторизацию. \n",
    "Также как и в предыдущем задании у классификаторов должно быть задано вручную как минимум 2 параметра (по возможности, f1 мера каждого из классификаторов должна быть минимум 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "81f86878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15af4e1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
